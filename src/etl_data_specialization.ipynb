{
	"cells": [
		{
			"cell_type": "markdown",
			"id": "dc7cacd1",
			"metadata": {
				"tags": []
			},
			"source": [
				"# Setup"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "be8535f4-4586-4d9c-9a28-8aa44f99ab35",
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"%idle_timeout 10\n",
				"%timeout 10\n",
				"%glue_version 4.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "a3fea417",
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"import boto3\n",
				"import os, sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from pyspark.sql.functions import *\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b20967d0-9c1b-4df7-ab6d-7a284aeffa9b",
			"metadata": {},
			"source": [
				"# Load data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "961d1433-cf6b-4d1c-92a9-16ac5f9878eb",
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Load dataframes\n",
				"df_taxas = spark.read.format('parquet').load(\"s3://tesouro-bronze/taxa_tesouro_direto.parquet\")\n",
				"df_operacoes = spark.read.format('parquet').load(\"s3://tesouro-bronze/operacoes_tesouro_direto.parquet\")\n",
				"df_investidores = spark.read.format('parquet').load(\"s3://tesouro-bronze/investidores_tesouro_direto.parquet\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "651e19a2-c9f2-4511-a48b-501eddbb64c2",
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Calculate the min and max dates from all date columns\n",
				"spark.sql(\"\"\"\n",
				"    SELECT `Data de Adesao` AS date FROM {df_investidores}\n",
				"    UNION ALL\n",
				"    SELECT `Data da Operacao` AS date FROM {df_operacoes}\n",
				"    UNION ALL\n",
				"    SELECT `Vencimento do Titulo` AS date FROM {df_operacoes}\n",
				"    UNION ALL\n",
				"    SELECT `Data Vencimento` AS date FROM {df_taxas}\n",
				"    UNION ALL\n",
				"    SELECT `Data Base` AS date FROM {df_taxas}\n",
				"\"\"\", df_taxas=df_taxas, df_operacoes=df_operacoes, df_investidores=df_investidores)\\\n",
				".createOrReplaceTempView(\"all_dates\")\n",
				"\n",
				"# Calculate the min and max dates using SQL\n",
				"max_date = spark.sql(\"SELECT MAX(date) as max_date FROM all_dates\").first()[\"max_date\"]\n",
				"min_date = spark.sql(\"SELECT MIN(date) as min_date FROM all_dates WHERE date <> '1900-01-01'\").first()[\"min_date\"]"
			]
		},
		{
			"cell_type": "markdown",
			"id": "efd8f90a-af6f-4126-9513-077cfb51eff4",
			"metadata": {
				"tags": []
			},
			"source": [
				"# Calendar dimension"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "7a4db5b0",
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Generate a date range based on the calculated min and max dates\n",
				"df_dates = spark.range(0, (max_date - min_date).days + 1).selectExpr(f\"DATE_ADD('{min_date}', CAST(id AS INT)) as date\")\n",
				"\n",
				"# Add calendar attributes\n",
				"df_calendario = df_dates\\\n",
				"    .withColumn(\"ano\", year(col(\"date\"))) \\\n",
				"    .withColumn(\"trimestre\", date_format(col(\"date\"), \"Q\").cast(\"int\")) \\\n",
				"    .withColumn(\"mes\", month(col(\"date\"))) \\\n",
				"    .withColumn(\"dia\", dayofmonth(col(\"date\"))) \\\n",
				"    .withColumn(\"dia da semana\", dayofweek(col(\"date\"))) \\\n",
				"    .withColumn(\"nome dia\", date_format(col(\"date\"), \"EEEE\")) \\\n",
				"    .withColumn(\"nome mes\", date_format(col(\"date\"), \"MMMM\")) \\\n",
				"    .withColumn(\"fim de semana\", when(col(\"dia da semana\").isin(1, 7), lit(1)).otherwise(lit(0)))\n",
				"\n",
				"# Write the DataFrame to a Parquet file in S3\n",
				"df_calendario.write.mode(\"overwrite\").parquet(\"s3://tesouro-silver/dim_calendario.parquet\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5e2eb9f9-5f20-4fc2-b8d4-623faea428cc",
			"metadata": {},
			"source": [
				"# Region dimension"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "fe733567-c7a4-4246-8a5e-f2483d8a4db2",
			"metadata": {
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Select and deduplicate the geographic fields\n",
				"df_region = df_investidores.select(\"UF do Investidor\", \"Cidade do Investidor\", \"Pais do Investidor\").distinct()\n",
				"df_region = df_region.withColumn(\"region_id\", row_number().over(Window.orderBy(monotonically_increasing_id()))-1)\n",
				"\n",
				"# Write the DataFrame to a Parquet file in S3\n",
				"df_region.write.mode(\"overwrite\").parquet(\"s3://tesouro-silver/dim_regiao.parquet\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f797d80b-971c-4635-910a-4fb09637440f",
			"metadata": {},
			"source": [
				"# Investidores dimension"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "66539c01-82a8-4add-943b-f45fc7d021fe",
			"metadata": {
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Add ID Cidade to the Investidores dimension\n",
				"df_dim_investidores = df_investidores.join(\n",
				"    df_region,\n",
				"    on=df_investidores[\"Cidade do Investidor\"] == df_investidores[\"Cidade do Investidor\"]\n",
				"    how=\"inner\"\n",
				").drop(\"UF do Investidor\", \"Cidade do Investidor\", \"Pais do Investidor\")\n",
				"\n",
				"df_dim_investidores.write.mode(\"overwrite\").parquet(\"s3://tesouro-silver/dim_investidores.parquet\")"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		},
		"toc-autonumbering": true,
		"toc-showcode": false,
		"toc-showmarkdowntxt": true
	},
	"nbformat": 4,
	"nbformat_minor": 5
}
